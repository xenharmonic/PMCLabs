{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 7: Working with impulse responses\n",
    "\n",
    "### 26 Feb 2018\n",
    "\n",
    "# Goals #\n",
    "\n",
    "After doing this lab, you should be able to:\n",
    "* Use convolution to apply other effects for a specific impulse response\n",
    "* Use listening, plotting waveforms, and plotting spectra to reason about the effects of convolution with an impulse response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.1. Are you caught up on labs?\n",
    "\n",
    "A portfolio of your first four labs was due on 16 February. If you haven't turned that in yet, please see the assignment here: https://learn.gold.ac.uk/mod/assign/view.php?id=514281\n",
    "\n",
    "By now, you should find it easy to:\n",
    "\n",
    "1. Synthesize a sine wave with an arbitrary amplitude, frequency, and phase offset, then play that wave back. If you don't know how to to this, revisit week 3's lab (https://learn.gold.ac.uk/mod/resource/view.php?id=512068)\n",
    "2. Compute and plot an FFT of an arbitrary 1-dimensional signal (e.g. an audio wave). If you don't know how to do this, revisit week 4's lab (https://learn.gold.ac.uk/mod/resource/view.php?id=512185)\n",
    "3. Use the spectrum computed by the FFT to reason about the frequencies in a sound (week 5: https://learn.gold.ac.uk/mod/resource/view.php?id=513559)\n",
    "\n",
    "__Don't forget that you may be asked about using Jupyter and Python for this type of synthesis and analysis on the exam, so now is the time to try it out and ask for help if you have problems!__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.2 Load audio files into Python variables #\n",
    "\n",
    "These are the same files as you used in last week's lab, so you may have them on your computer already! If so, just make sure they're copied to the same directory as this Notebook file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. Download the following audio files and store them in the same directory as this lab file:\n",
    "* http://www.doc.gold.ac.uk/~mas01rf/PMC2014-15/IPython/lab14/noise.wav\n",
    "* http://www.doc.gold.ac.uk/~mas01rf/PMC2014-15/IPython/lab14/robot.wav\n",
    "* http://www.doc.gold.ac.uk/~mas01rf/PMC2014-15/IPython/lab14/saw.wav\n",
    "* http://www.doc.gold.ac.uk/~mas01rf/PMC2014-15/IPython/lab14/sinMandolin1.wav\n",
    "* http://www.doc.gold.ac.uk/~mas01rf/PMC2014-15/IPython/lab14/sinMandolin2.wav\n",
    "* http://www.doc.gold.ac.uk/~mas01rf/PMC2014-15/IPython/lab13/song1.wav\n",
    "\n",
    "(This last one is an exceprt downloaded from \n",
    "\n",
    "http://freemusicarchive.org/music/Jahzzar/Travellers_Guide/Siesta)\n",
    "\n",
    "b. Now load them into variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "noise = wavReadMono(\"noise.wav\")\n",
    "robot = wavReadMono(\"robot.wav\")\n",
    "saw = wavReadMono(\"saw.wav\")\n",
    "sinMandolin1 = wavReadMono(\"sinMandolin1.wav\")\n",
    "sinMandolin2 = wavReadMono(\"sinMandolin2.wav\")\n",
    "song1 = wavReadMono(\"song1.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Listen to them if you'd like:\n",
    "play(song1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Using Convolution for Audio Effects #\n",
    "\n",
    "*Part 1 here duplicates Part 3 of last week's lab. If you did this already, please initialise your variables using the code below before skipping to Part 2*\n",
    "\n",
    "As we saw in lecture last week, many audio effects (\"systems\") are applied by __convolving a sound with a special signal, called an impulse response__.\n",
    "\n",
    "Run the code below to specify two impulse response signals, `h1` and `h2`. Notice that these signals are simply __arrays__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h1 = [0.5, 0.5]\n",
    "h2 = [1/10, 1/10, 1/10, 1/10, 1/10, 1/10, 1/10, 1/10, 1/10, 1/10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure you've run the code in Part 0.2 to load audio clips into `song1` and `noise`. Then run the code below to apply the simple effects represented by `h1` and `h2` to `song1` and `noise`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "song1_h1 = convolve(song1, h1)\n",
    "song1_h2 = convolve(song1, h2)\n",
    "noise_h1 = convolve(noise, h1)\n",
    "noise_h2 = convolve(noise, h2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now listen to `song1`, `song1_h1`, and `song1_h2`. Do you hear a difference? If so, what?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "play(song1)\n",
    "play(song1_h1)\n",
    "play(song1_h2)\n",
    "# If you get this error: \"IOPub data rate exceeded.\", \n",
    "# then try commenting out one or two of these play functions before running"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now listen to `noise`, `noise_h1`, and `noise_h2`. Do you hear a difference? If so, what?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "play(noise)\n",
    "play(noise_h1)\n",
    "play(noise_h2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the first 100 samples of `song1`, `song1_h1`, and `song1_h2`. How do they compare?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#fill this in and discuss how they compare\n",
    "plot(...\n",
    "plot(...\n",
    "plot(..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now do the same thing for the first 100 samples of `noise`, `noise_h1`, and `noise_h2`. What is the relationship between them?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fill this in and discuss the relationship between these signals\n",
    "plot(...\n",
    "plot(...\n",
    "plot(..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, what effects do convolving a sound with `h1` and `h2` seem to have on the waveforms?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write your answer here (double-click to edit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now compare the __spectra__ of `song1`, `song1_h1`, and `song1_h2`, as well as the spectra of `noise`, `noise_h1`, and `noise_h2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Plot and compare the spectra here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, what effects do convolving a sound with `h1` and `h2` seem to have on the spectra?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write your answer here (double-click to edit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Reasoning about filters h1 and h2 #\n",
    "\n",
    "If `h1` is the impulse response for a system H1, what type of system is H1?\n",
    "\n",
    "Likewise, if `h2` is the impulse response for a system H2, what type of system is H2? \n",
    "\n",
    "In this section, we will look at the __spectra__ of `h1` and `h2` to understand that they are both functioning as __low-pass filters__.\n",
    "\n",
    "Start by ensuring that `h1`, `h2`, `noise`, `song1`, `song1_h1`, `song1_h2`, `noise_h1`, and `noise_h2` are still initialised from Part 1, above, by running those cells if you haven't already. \n",
    "\n",
    "Let's take a look at the FFT of `h1`. Note that `h1` is only 2 samples long, and a 2-point FFT doesn't give us that much information!\n",
    "\n",
    "However, remember that we can assume that a signal has a value of 0 for any time point not explicitly specified, so we could equivalently set `h1` to be equal to [0.5, 0.5, 0.0] or to [0.5, 0.5, 0.0, 0.0, 0.0], etc.\n",
    "\n",
    "Let's make a new variable, `h1_1024`, that is a 1024 sample long version of `h1`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h1_1024 = concatenate([h1, zeros(1022)])\n",
    "print \"h1_1024 is now: \", h1_1024, \", with length \", size(h1_1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, compute and plot the FFT of `h1_1024`, remembering to plot only the first 512 elements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Hint: Your spectrum should look like <a href = \"http://www.doc.gold.ac.uk/~mas01rf/PMC2016-17/lab16/h1_spectrum.png\">this</a>. If it doesn't, try to figure out where you went wrong before going on!*|\n",
    "\n",
    "Note that the magnitude of the FFT bins is near 1 for the lower-frequency bins (i.e., near 0 Hz), and drops off to 0 for the higher-frequency bins (i.e., those near the Nyquist rate). \n",
    "\n",
    "Why is this important? __It turns out that convolving an input signal with an impulse response computes a new signal, whose spectrum is equal to the input signal's spectrum multiplied, bin-by-bin, with the spectrum of the impulse response!!__ \n",
    "\n",
    "Now plot the spectrum of `noise` on one plot, and the spectrum of `\n",
    "noise_h1` on a second plot. Note the similarity in shape between the spectrum of `noise_h1` and the spectrum of `h1`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#plot the spectrum of noise, up to the nyquist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#plot the spectrum of noise_h1, up to the nyquist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Hint: The spectrum of `noise_h1` should look like <a href = \"http://www.doc.gold.ac.uk/~mas01rf/PMC2016-17/lab16/noise_h1_spectrum.png\">this</a>. If it doesn't, figure out where you went wrong before going on.*\n",
    "\n",
    "Notice that the spectrum of `filtered_noise_h1` looks like you've multiplied, bin-by-bin, the spectrum of `noise` and the spectrum of `h1`.\n",
    "\n",
    "So, let's say it again:\n",
    "\n",
    "# <font color = \"red\">Convolving an input signal with an impulse response yields an output signal whose spectrum is equal to the input signal's spectrum multiplied bin-by-bin with the impulse response's spectrum!</font> #\n",
    "\n",
    "Now, repeat the process with `h2`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Make a new variable, h2_1024, that is a 1024 sample long version of h2:\n",
    "h2_1024 = concatenate([h2, zeros(1014)])\n",
    "print \"h2_1024 is now: \", h2_1024, \", with length \", size(h2_1024)\n",
    "\n",
    "#Plot the spectrum of h2_1024:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Now plot the spectrum of noise_h2 and compare its shape to h2_1024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, repeat this process, trying to understand how the spectra of `song1` and `h1` combine to create the spectrum of `song1_h1`. Repeat again with `song1`, `h2`, and `song1_h2`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It should now be apparent to you that `h1` and `h2` are acting as __low-pass filters__. That is, lower frequencies __pass through__ relatively unchanged, but higher frequencies are reduced in magnitude or cut out completely."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: Another filter #\n",
    "a. Create a new filter whose impulse response `h3` is [-1, 1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Plot the frequency response of `h3` (don't forget to add 0s to the end, and don't forget to plot only up until the Nyquist rate!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__ What kind of filter is h3? __\n",
    "\n",
    "__ What do you think the perceptual effect of h3 will be on your sounds? __"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Double-click here to edit and add your answers*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. Apply h3 to the sounds `noise`, `robot`, and `saw`.\n",
    "\n",
    "__ You will need to renormalize each of your sounds after filtering so that they don't contain any values less than -1 or more than 1! __\n",
    "\n",
    "Use the following approach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#convolve as usual\n",
    "tmp = convolve(noise, h3)\n",
    "\n",
    "#normalize: divide by the maximum absolute value in the signal:\n",
    "noise_h3 = tmp / (max(abs(tmp)))\n",
    "\n",
    "#repeat for robot and saw\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d. Plot the spectra for these new sounds and compare them to the spectrum of h3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your work here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__ e. If you're interested in experimenting more with simple audio filters, try applying h1, h10, and h3 to the other sounds you loaded in above. Listen to the filtered results and plot the spectra of the filtered signals. __"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus Material #\n",
    "\n",
    "If you've gotten this far, great! Here are a few things you should know:\n",
    "\n",
    "1. The spectrum of a system's impulse response is called its \"frequency response.\" The magnitude of each bin in this spectrum tells us how that frequency will be scaled by the system, for any new input. \n",
    "2. We can also look at the __phase__ of each spectral bin, which tells us how much that frequency will be shifted in phase by the system, for any new input.\n",
    "3. Python provides you built-in functions to plot the magnitude and phase responses for a filter. \n",
    "\n",
    "For instance the function `signal.freqz` computes the frequency response for a filter, which can easily be plotted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w, h = signal.freqz(h1) #get frequency response for h1\n",
    "fig = plt.figure()\n",
    "plt.title('Digital filter frequency response')\n",
    "ax1 = fig.add_subplot(111)\n",
    "\n",
    "plt.plot(w, 20 * np.log10(abs(h)), 'b') #plot in dB scale, wow!\n",
    "plt.ylabel('Amplitude [dB]', color='b')\n",
    "plt.xlabel('Frequency [rad/sample]')\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "angles = np.unwrap(np.angle(h))\n",
    "plt.plot(w, angles, 'g')\n",
    "plt.ylabel('Angle (radians)', color='g')\n",
    "plt.grid()\n",
    "plt.axis('tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, Python gives you tools that can help you *design* new filters with desired properties.\n",
    "\n",
    "For instance, the function `signal.firwin` allows you to build low-pass, high-pass, band-pass, band-stop, and multi-band filters! Read the documentation, making sure you scroll all the way down to see the example code for each filter type: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?signal.firwin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also find great third-party libraries to help with filter design and plotting. For example check out http://mpastell.com/2010/01/18/fir-with-scipy/ (requires you to download http://files.mpastell.com/FIR_design.py and run the function definitions there)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# HAVE FUN NOW"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
